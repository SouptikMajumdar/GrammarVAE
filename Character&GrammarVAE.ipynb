{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Notebook for Our AE, VAE and Grammar Constrained VAE Experiments\n",
    "    + Contains MLFlow Pipeline for all three architectures\n",
    "    + Model architectures/classes are defined in models.py\n",
    "    + Training Methods are defined in train.py\n",
    "    + Evaluations for Test are defined in eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "print(\"Using torch\", torch.__version__)\n",
    "import seaborn as sns\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "sns.set()\n",
    "torch.manual_seed(42)\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from ac_dll_grammar_vae import print_contact_info\n",
    "from ac_dll_grammar_vae.data import CFGEquationDataset\n",
    "from ac_dll_grammar_vae.data.alphabet import alphabet\n",
    "from ac_dll_grammar_vae.data.transforms import MathTokenEmbedding, RuleTokenEmbedding, ToTensor, Compose, PadSequencesToSameLengthV2, OneHotEncode\n",
    "from train import *\n",
    "from eval import *\n",
    "from visualize import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)\n",
    "\n",
    "# GPU operations have a separate seed we also want to set\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
    "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "#device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character AE and VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Embedding: We use MathTokenEmbedding class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = MathTokenEmbedding(alphabet=alphabet)\n",
    "#emb.token_to_idx #For Displaying the Embedding --> Uncomment this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Data and Encoding from Equation Dataset Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = CFGEquationDataset()\n",
    "#Example Encoding:\n",
    "print(f'Example: Data {data[42]}')\n",
    "encoded_data = emb.embed(data[42])\n",
    "print(f'Encoded Example: Data {encoded_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Size and Maximum Equation Length Setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "MAX_SEQ_LEN = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = CFGEquationDataset(\n",
    "        n_samples=100000,\n",
    "        transform=Compose([\n",
    "            MathTokenEmbedding(alphabet),\n",
    "            ToTensor(dtype=torch.uint8)\n",
    "        ]))\n",
    "collate_fn = PadSequencesToSameLengthV2(padding_value=0, max_length=MAX_SEQ_LEN)\n",
    "training_loader = DataLoader(dataset=training,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=PadSequencesToSameLengthV2(padding_value=0, max_length=MAX_SEQ_LEN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the Embedded equations into one hot encoded vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncode(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_training = []\n",
    "for batch in training_loader:\n",
    "  try:\n",
    "    one_hot_encoded_batch = onehotencoder(batch)\n",
    "  except Exception as e:\n",
    "    #print(batch)\n",
    "    continue\n",
    "  one_hot_encoded_training.append(one_hot_encoded_batch.numpy())\n",
    "one_hot_encoded_training = np.array(one_hot_encoded_training)\n",
    "one_hot_encoded_training_tensor = torch.Tensor(one_hot_encoded_training)\n",
    "one_hot_encoded_training_tensor = one_hot_encoded_training_tensor.view(one_hot_encoded_training_tensor.shape[0]*one_hot_encoded_training_tensor.shape[1],one_hot_encoded_training_tensor.shape[2],one_hot_encoded_training_tensor.shape[3])\n",
    "one_hot_encoded_training_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating final dataloader for model which is one-hot-encoded:\n",
    " + Setting Maximum equation length to 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_length = len(alphabet) + 1\n",
    "one_hot_encoded_training_loader = DataLoader(dataset=one_hot_encoded_training_tensor,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Test Dataset and Dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CFGEquationDataset(\n",
    "        n_samples=10000,\n",
    "        transform=Compose([\n",
    "            MathTokenEmbedding(alphabet),\n",
    "            ToTensor(dtype=torch.uint8)\n",
    "        ]))\n",
    "collate_fn = PadSequencesToSameLengthV2(padding_value=0, max_length=MAX_SEQ_LEN)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=PadSequencesToSameLengthV2(padding_value=0, max_length=MAX_SEQ_LEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_testing = []\n",
    "for batch in test_loader:\n",
    "  try:\n",
    "    one_hot_encoded_batch = onehotencoder(batch)\n",
    "  except Exception as e:\n",
    "    #print(batch)\n",
    "    continue\n",
    "  #print(one_hot_encoded_batch.shape)\n",
    "  one_hot_encoded_testing.append(one_hot_encoded_batch.numpy())\n",
    "one_hot_encoded_testing = np.array(one_hot_encoded_testing)\n",
    "one_hot_encoded_testing_tensor = torch.Tensor(one_hot_encoded_testing)\n",
    "one_hot_encoded_testing_tensor = one_hot_encoded_testing_tensor.view(one_hot_encoded_testing_tensor.shape[0]*one_hot_encoded_testing_tensor.shape[1],one_hot_encoded_testing_tensor.shape[2],one_hot_encoded_testing_tensor.shape[3])\n",
    "#print(one_hot_encoded_testing_tensor.shape)\n",
    "one_hot_encoded_testing_loader = DataLoader(dataset=one_hot_encoded_testing_tensor,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import EqnAE from models, train_AEModel from train and Model Initialization for Character AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import EqnAE\n",
    "from train import train_AEmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()  #Ensure no current mlflow experiment is running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AE Experiment and Hyperparamter Searching using mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from hyperparam_optim import HyperparameterOptimization\n",
    "from tracking import MLFlowTracker\n",
    "import itertools\n",
    "from visualize import *\n",
    "\n",
    "hyperParamOptimization = HyperparameterOptimization('./hyperparameters/params.yaml')\n",
    "params = hyperParamOptimization.get_params()\n",
    "\n",
    "mlflow.set_experiment('Character AE Equation V3')\n",
    "\n",
    "\n",
    "hyperparameter_combinations = itertools.product(params.M_LATENTDIMENSION, params.T_NUMEPOCHS, params.T_LR, params.T_BATCHSIZE, params.T_LOSS, params.T_OPTIMIZER, params.T_TRAINVALIDRATIO)\n",
    "for combination in hyperparameter_combinations:\n",
    "    mlflow.start_run()\n",
    "    latent_dim, num_epochs, lr, batch_size, loss_function, optimizer_name, train_valid_ratio = combination\n",
    "\n",
    "    # Initialize your model with the given latent dimension\n",
    "    # Model Initialization\n",
    "    alphabet_length = len(alphabet) + 1\n",
    "    MAX_SEQ_LEN = 21\n",
    "    model = EqnAE(alphabet_length,MAX_SEQ_LEN,latent_rep_size=latent_dim)\n",
    "    model.to(device)\n",
    "    #Loss\n",
    "    if loss_function == 'BCE':\n",
    "        loss_module = nn.BCELoss(reduction=\"sum\")\n",
    "    elif loss_function == 'MSE':\n",
    "        loss_module = nn.MSELoss(reduction=\"sum\")\n",
    "    \n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'Adadelta':\n",
    "        optimizer = torch.optim.Adadelta(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'Adagrad':\n",
    "        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'RMSprop':\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(),lr=lr)\n",
    "\n",
    "    total_samples = one_hot_encoded_training_tensor.shape[0]\n",
    "    valid_size = int(total_samples * train_valid_ratio)\n",
    "    train_size = total_samples - valid_size\n",
    "\n",
    "    train_tensor = one_hot_encoded_training_tensor[:train_size]\n",
    "    valid_tensor = one_hot_encoded_training_tensor[train_size:]\n",
    "\n",
    "    train_dataset = TensorDataset(train_tensor)\n",
    "    val_dataset = TensorDataset(valid_tensor) \n",
    "\n",
    "    train_loader = DataLoader(dataset=train_tensor,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False)\n",
    "\n",
    "    val_loader = DataLoader(dataset=valid_tensor,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False)\n",
    "\n",
    "    # Log parameters to MLflow\n",
    "    mlflow.log_params({\n",
    "        \"latent_dimension\": latent_dim,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"learning_rate\": lr,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"loss_function\": loss_function,\n",
    "        \"optimizer\": optimizer_name,\n",
    "        \"train_valid_ratio\": train_valid_ratio\n",
    "    })\n",
    "\n",
    "    #Start Training\n",
    "    train_EqnAE(model, train_loader, val_loader, loss_module, optimizer, num_epochs=num_epochs)\n",
    "\n",
    "    #Save the Model locally if required:\n",
    "    #torch.save(model,f'./saved/models/EQN_AE_{latent_dim}_{batch_size}_{loss_function}_{lr}_{num_epochs}_{optimizer_name}_{train_valid_ratio}_Full.pth')\n",
    "    #torch.save(model.state_dict(),f'./saved/models/EQN_AE_{latent_dim}_{batch_size}_{loss_function}_{lr}_{num_epochs}_{optimizer_name}_{train_valid_ratio}_dict.pth')\n",
    "\n",
    "    # Save the model using MlFlow\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "    test_tensor = one_hot_encoded_testing_tensor\n",
    "    test_dataset = TensorDataset(test_tensor)\n",
    "    test_loader = DataLoader(dataset=test_tensor,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False)             \n",
    "    model.to(device)\n",
    "    \n",
    "    #Visualization of Results\n",
    "    #visualize_latent_space_Eqn(model, test_loader,False)\n",
    "    dummy = CFGEquationDataset()\n",
    "    cfg = dummy.get_grammar()\n",
    "    visualize_latent_space_Eqn_PCA(model, test_loader,False,False,cfg,n=30)\n",
    "    mlflow.log_artifact(\"./plots/PCA_LatentSpace_plot.png\", artifact_path=\"plots\")\n",
    "\n",
    "    one_hot_decoded = []\n",
    "    one_hot_decoded_recon = []\n",
    "    recon_losses = []\n",
    "    model.eval()\n",
    "    criterion = torch.nn.BCELoss(reduction='sum')\n",
    "    for sample in test_loader:\n",
    "        sample = sample.float().to(device)\n",
    "        recon = model(sample)\n",
    "        for idx,ele in enumerate(recon):\n",
    "            recon_loss = criterion(ele,sample[idx])\n",
    "            max_indices = torch.argmax(ele, dim=1)\n",
    "            one_hot = torch.zeros_like(ele) \n",
    "            one_hot[torch.arange(ele.size(0)), max_indices] = 1\n",
    "            embd = torch.argmax(one_hot, dim=1)\n",
    "            one_hot_decoded.append(emb.decode(torch.argmax(sample[idx], dim=1)))\n",
    "            one_hot_decoded_recon.append(emb.decode(embd))\n",
    "            recon_losses.append(recon_loss)\n",
    "            recon_loss = 0\n",
    "\n",
    "        output_filename = f\"./output/output_{latent_dim}_{batch_size}_{loss_function}_{lr}_{num_epochs}_{optimizer_name}_{train_valid_ratio}.txt\"\n",
    "        with open(output_filename, \"w\") as file:\n",
    "            for idx, ele in enumerate(one_hot_decoded_recon[:1000]):\n",
    "                actual_equation = ''.join(one_hot_decoded[idx])\n",
    "                decoded_equation = ''.join(one_hot_decoded_recon[idx])\n",
    "                file.write(f'Actual Equation: {actual_equation}\\n')\n",
    "                file.write(f'AE Decoded Equation: {decoded_equation}\\n')\n",
    "                file.write(f'AE Reconstruction Loss: {recon_losses[idx]}\\n\\n')\n",
    "                \n",
    "        # Log the file as an artifact in MLflow\n",
    "        mlflow.log_artifact(output_filename, artifact_path=\"outputs\")\n",
    "\n",
    "    test_loss = eval_modelAEEquations(model,test_loader,loss_module)\n",
    "    mlflow.log_metric(\"Test Loss\", test_loss)\n",
    "\n",
    "    # End MLflow run\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import EqnVAE\n",
    "from train import train_EqnVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization and Hyperparameter Optimization for Character VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from hyperparam_optim import HyperparameterOptimization\n",
    "from tracking import MLFlowTracker\n",
    "import itertools\n",
    "from visualize import *\n",
    "import gc\n",
    "import time\n",
    "\n",
    "hyperParamOptimization = HyperparameterOptimization('./hyperparameters/params.yaml')\n",
    "params = hyperParamOptimization.get_params()\n",
    "\n",
    "#mlflow.create_experiment('Character VAE Equation V2')\n",
    "mlflow.set_experiment('Character VAE Equation V3')\n",
    "\n",
    "hyperparameter_combinations = itertools.product(params.M_LATENTDIMENSION, params.T_NUMEPOCHS, params.T_LR, params.T_BATCHSIZE, params.T_LOSS, params.T_OPTIMIZER, params.T_TRAINVALIDRATIO)\n",
    "for i,combination in enumerate(hyperparameter_combinations):\n",
    "    # if i <= 1:\n",
    "    #     continue\n",
    "    mlflow.start_run()\n",
    "    latent_dim, num_epochs, lr, batch_size, loss_function, optimizer_name, train_valid_ratio = combination\n",
    "\n",
    "    # Initialize your model with the given latent dimension\n",
    "    # Model Initialization\n",
    "    alphabet_length = len(alphabet) + 1\n",
    "    MAX_SEQ_LEN = 21\n",
    "    model = None\n",
    "    model = EqnVAE(alphabet_length,MAX_SEQ_LEN,latent_rep_size=latent_dim,recon_loss=loss_function)\n",
    "    model.to(device)\n",
    "    #Loss\n",
    "    vaeLoss = None\n",
    "    vaeLoss = model.vae_loss\n",
    "    optimizer = None\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'Adadelta':\n",
    "        optimizer = torch.optim.Adadelta(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'Adagrad':\n",
    "        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'RMSprop':\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(),lr=lr)\n",
    "\n",
    "    total_samples = one_hot_encoded_training_tensor.shape[0]\n",
    "    valid_size = int(total_samples * train_valid_ratio)\n",
    "    train_size = total_samples - valid_size\n",
    "\n",
    "    train_tensor = one_hot_encoded_training_tensor[:train_size].clone().to(device)\n",
    "    valid_tensor = one_hot_encoded_training_tensor[train_size:].clone().to(device)\n",
    "    train_loader, val_loade = None, None\n",
    "    train_loader = DataLoader(dataset=train_tensor,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False)\n",
    "\n",
    "    val_loader = DataLoader(dataset=valid_tensor,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False)\n",
    "\n",
    "    # Log parameters to MLflow\n",
    "    mlflow.log_params({\n",
    "        \"latent_dimension\": latent_dim,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"learning_rate\": lr,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"loss_function\": loss_function,\n",
    "        \"optimizer\": optimizer_name,\n",
    "        \"train_valid_ratio\": train_valid_ratio\n",
    "    })\n",
    "\n",
    "    train_EqnVAE(model, train_loader, val_loader, vaeLoss, optimizer, num_epochs=num_epochs)\n",
    "\n",
    "    \n",
    "    #torch.save(model,f'./saved/models/EQN_VAE_{latent_dim}_{batch_size}_{loss_function}_{lr}_{num_epochs}_{optimizer_name}_{train_valid_ratio}_Full.pth')\n",
    "    #torch.save(model.state_dict(),f'./saved/models/EQN_VAE_{latent_dim}_{batch_size}_{loss_function}_{lr}_{num_epochs}_{optimizer_name}_{train_valid_ratio}_dict.pth')\n",
    "\n",
    "    # Save the model using mlflow\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "    test_tensor = one_hot_encoded_testing_tensor.clone().to(device)\n",
    "    test_dataset = TensorDataset(test_tensor)\n",
    "    test_loader = DataLoader(dataset=test_tensor,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False)             \n",
    "    model.to(device)\n",
    "    \n",
    "    #Visualize Results for VAE\n",
    "    dummy = CFGEquationDataset()\n",
    "    cfg = dummy.get_grammar()\n",
    "    visualize_latent_space_Eqn_PCA(model, test_loader,True,False,cfg,n=30)\n",
    "    mlflow.log_artifact(\"./plots/PCA_LatentSpace_plot.png\", artifact_path=\"plots\")\n",
    "    vis_interpolation(model,test_loader,vae=True,n=20,seed=42)\n",
    "    mlflow.log_artifact(\"./plots/PCA_Interpolation_plot.png\", artifact_path=\"plots\")\n",
    "\n",
    "    one_hot_decoded = []\n",
    "    one_hot_decoded_recon = []\n",
    "    recon_losses = []\n",
    "    model.eval()\n",
    "    criterion = torch.nn.BCELoss(reduction='sum')\n",
    "    for sample in test_loader:\n",
    "        sample = sample.float().to(device)\n",
    "        recon, _, _ = model(sample)\n",
    "        for idx,ele in enumerate(recon):\n",
    "            recon_loss = criterion(ele,sample[idx])\n",
    "            max_indices = torch.argmax(ele, dim=1)\n",
    "            one_hot = torch.zeros_like(ele) \n",
    "            one_hot[torch.arange(ele.size(0)), max_indices] = 1\n",
    "            embd = torch.argmax(one_hot, dim=1)\n",
    "            one_hot_decoded.append(emb.decode(torch.argmax(sample[idx], dim=1)))\n",
    "            one_hot_decoded_recon.append(emb.decode(embd))\n",
    "            recon_losses.append(recon_loss)\n",
    "            recon_loss = 0\n",
    "\n",
    "        output_filename = f\"./output/output_{latent_dim}_{batch_size}_{loss_function}_{lr}_{num_epochs}_{optimizer_name}_{train_valid_ratio}.txt\"\n",
    "        with open(output_filename, \"w\") as file:\n",
    "            for idx, ele in enumerate(one_hot_decoded_recon[:1000]):\n",
    "                actual_equation = ''.join(one_hot_decoded[idx])\n",
    "                decoded_equation = ''.join(one_hot_decoded_recon[idx])\n",
    "                file.write(f'Actual Equation: {actual_equation}\\n')\n",
    "                file.write(f'VAE Decoded Equation: {decoded_equation}\\n')\n",
    "                file.write(f'VAE Reconstruction Loss: {recon_losses[idx]}\\n\\n')\n",
    "\n",
    "        # Log the file as an artifact in MLflow\n",
    "        mlflow.log_artifact(output_filename, artifact_path=\"outputs\")\n",
    "\n",
    "    test_loss = eval_modelVAEEquations(model,test_loader,vaeLoss)\n",
    "    mlflow.log_metric(\"Test Loss\", test_loss)\n",
    "\n",
    "    # Clear memory\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()  # Clear cached memory\n",
    "        torch.cuda.manual_seed_all(42)  # Re-seed\n",
    "\n",
    "    # Wait for 5-10 seconds before the next run\n",
    "    \n",
    "    # End MLflow run\n",
    "    mlflow.end_run()\n",
    "    time.sleep(5)  # Sleep for 5 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed Equations to Rule instead of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rules Embedding\n",
    "data = CFGEquationDataset()\n",
    "cfg = data.get_grammar()\n",
    "emb = RuleTokenEmbedding(cfg=cfg,one_hot_encode=True)\n",
    "#emb.idx_to_rule #Uncomment to show embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intializing Grammar Masks and Mask Index for Introducing into Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [0, 1], [0, 1], [0, 1], [1], [0], [0], [0], [0], [0], [0], [], [], [], [], []]\n",
      "[[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "[0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# Parsing the grammar to create masks and indices\n",
    "all_lhs = [a.lhs().symbol() for a in cfg.productions()]\n",
    "lhs_list = []\n",
    "for a in all_lhs:\n",
    "    if a not in lhs_list:\n",
    "        lhs_list.append(a)\n",
    "D = len(cfg.productions())\n",
    "\n",
    "rhs_map = [None] * D\n",
    "for i, production in enumerate(cfg.productions()):\n",
    "    rhs_map[i] = [lhs_list.index(b.symbol()) for b in production.rhs() if (isinstance(b, nltk.Nonterminal) and b.symbol()!='None')]\n",
    "\n",
    "print(rhs_map)\n",
    "\n",
    "masks = np.zeros((len(lhs_list), D))\n",
    "for i, lhs in enumerate(lhs_list):\n",
    "    masks[i] = [lhs == production.lhs().symbol() for production in cfg.productions()]\n",
    "\n",
    "print(masks)\n",
    "ind_of_ind = np.array([np.where(masks[:, i] == 1)[0][0] for i in range(masks.shape[1])])\n",
    "print(ind_of_ind)\n",
    "# Convert numpy arrays to torch tensors\n",
    "masks_tensor = torch.from_numpy(masks).float()\n",
    "ind_of_ind_tensor = torch.from_numpy(ind_of_ind).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Encoding of an equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eqn = ['sqrt','(','log','(','x','*','cos','(','2',')',')',')','*','x']\n",
    "encoded_gram_eqn = emb.embed(eqn)\n",
    "encoded_gram_eqn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grammar VAE Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import EqnGVAE\n",
    "from train import train_EqnGVAE\n",
    "from eval import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation for GVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rules = len(cfg.productions())\n",
    "training_val_gvae_dataset = CFGEquationDataset(\n",
    "        n_samples=100000,\n",
    "        transform=Compose([\n",
    "            RuleTokenEmbedding(cfg,max_num_rules=16,one_hot_encode=True),\n",
    "            ToTensor(dtype=torch.uint8)\n",
    "        ]))\n",
    "\n",
    "#Batch Size:\n",
    "batch_size = 100\n",
    "MAX_PROD_LEN = 16\n",
    "\n",
    "test_gvae_dataset = CFGEquationDataset(\n",
    "        n_samples=10000,\n",
    "        transform=Compose([\n",
    "            RuleTokenEmbedding(cfg,max_num_rules=16,one_hot_encode=True),\n",
    "            ToTensor(dtype=torch.uint8)\n",
    "        ]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training of GVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from hyperparam_optim import HyperparameterOptimization\n",
    "from tracking import MLFlowTracker\n",
    "import itertools\n",
    "from visualize import visualize_latent_space_Eqn\n",
    "import gc\n",
    "import time\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "hyperParamOptimization = HyperparameterOptimization('./hyperparameters/params.yaml')\n",
    "params = hyperParamOptimization.get_params()\n",
    "\n",
    "mlflow.set_experiment('Grammar VAE Equation V3')\n",
    "\n",
    "hyperparameter_combinations = itertools.product(params.M_LATENTDIMENSION, params.T_NUMEPOCHS, params.T_LR, params.T_BATCHSIZE, params.T_LOSS, params.T_OPTIMIZER, params.T_TRAINVALIDRATIO)\n",
    "for i,combination in enumerate(hyperparameter_combinations):\n",
    "    # if i <= 1:\n",
    "    #     continue\n",
    "    mlflow.start_run()\n",
    "    latent_dim, num_epochs, lr, batch_size, loss_function, optimizer_name, train_valid_ratio = combination\n",
    "\n",
    "    # Initialize your model with the given latent dimension\n",
    "    # Model Initialization\n",
    "    model = None\n",
    "    model = EqnGVAE(num_rules,MAX_PROD_LEN,masks_tensor=masks_tensor,ind_of_masks=ind_of_ind_tensor)\n",
    "    model.to(device)\n",
    "    #Loss\n",
    "    vaeLoss = None\n",
    "    vaeLoss = model.vae_loss\n",
    "    optimizer = None\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'Adadelta':\n",
    "        optimizer = torch.optim.Adadelta(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'Adagrad':\n",
    "        optimizer = torch.optim.Adagrad(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'RMSprop':\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(),lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "    total_samples = len(training_val_gvae_dataset)\n",
    "    valid_size = int(total_samples * train_valid_ratio)\n",
    "    train_size = total_samples - valid_size\n",
    "\n",
    "    train_dataset, valid_dataset = random_split(training_val_gvae_dataset, [train_size, valid_size])\n",
    "    train_loader, val_loader = None, None\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "\n",
    "    val_loader = DataLoader(dataset=valid_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "\n",
    "    # Log parameters to MLflow\n",
    "    mlflow.log_params({\n",
    "        \"latent_dimension\": latent_dim,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"learning_rate\": lr,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"loss_function\": loss_function,\n",
    "        \"optimizer\": optimizer_name,\n",
    "        \"train_valid_ratio\": train_valid_ratio\n",
    "    })\n",
    "\n",
    "    train_EqnGVAE(model, train_loader, val_loader, vaeLoss, optimizer, num_epochs=num_epochs)\n",
    "\n",
    "\n",
    "    #torch.save(model,f'./saved/models/EQN_GVAE_{latent_dim}_{batch_size}_{loss_function}_{lr}_{num_epochs}_{optimizer_name}_{train_valid_ratio}_Full.pth')\n",
    "    #torch.save(model.state_dict(),f'./saved/models/EQN_GVAE_{latent_dim}_{batch_size}_{loss_function}_{lr}_{num_epochs}_{optimizer_name}_{train_valid_ratio}_dict.pth')\n",
    "\n",
    "    # Save the model\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "    test_dataset = test_gvae_dataset\n",
    "    test_loader = DataLoader(dataset=test_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False)\n",
    "    model.to(device)\n",
    "\n",
    "    test_loss = eval_modelVAEEquations(model,test_loader,vaeLoss)\n",
    "    mlflow.log_metric(\"Test Loss\", test_loss)\n",
    "\n",
    "    #visualize_latent_space_EqnGVAE(model,test_loader,max_num_rules=16,cfg=cfg,vae=True)\n",
    "    visualize_latent_space_Eqn_PCA(model, test_loader,True,True,cfg,n=30)\n",
    "    mlflow.log_artifact(\"./plots/PCA_LatentSpace_plot.png\", artifact_path=\"plots\")\n",
    "\n",
    "    equations_rules_decoded, equations_rules_actual, recon_losses = sample_fromGVAE(model,test_loader,masks_tensor,ind_of_ind_tensor,max_length=16,num_rules=16,emb=emb)\n",
    "    output_filename = f\"./output/output_{latent_dim}_{batch_size}_{loss_function}_{lr}_{num_epochs}_{optimizer_name}_{train_valid_ratio}.txt\"\n",
    "    with open(output_filename, \"w\") as file:\n",
    "        for idx, rule_decoded in enumerate(equations_rules_decoded):\n",
    "            file.write(f'Actual Equation Rules: {equations_rules_actual[idx]}\\n')\n",
    "            file.write(f'GVAE Decoded Equation Rules: {rule_decoded}\\n')\n",
    "            file.write(f'Recontruction Loss: {recon_losses[idx]}\\n\\n')\n",
    "\n",
    "    mlflow.log_artifact(output_filename, artifact_path=\"outputs\")\n",
    "\n",
    "    output_filename = f\"./output/output_rule_{latent_dim}_{batch_size}_{loss_function}_{lr}_{num_epochs}_{optimizer_name}_{train_valid_ratio}.txt\"\n",
    "    emb_dec = RuleTokenEmbedding(cfg=cfg,one_hot_encode=False)\n",
    "    with open(output_filename, \"w\") as file:\n",
    "        for idx, ele in enumerate(equations_rules_decoded):\n",
    "            actual_equation = ''.join(emb_dec.decode_from_sampled_rules(equations_rules_actual[idx]))\n",
    "            decoded_equation = ''.join(emb_dec.decode_from_sampled_rules(ele))\n",
    "            file.write(f'Actual Equation: {actual_equation}\\n')\n",
    "            file.write(f'GVAE Decoded Equation: {decoded_equation}\\n')\n",
    "            file.write(f'Recontruction Loss: {recon_losses[idx]}\\n\\n')\n",
    "\n",
    "        # Log the file as an artifact in MLflow\n",
    "    mlflow.log_artifact(output_filename, artifact_path=\"outputs\")\n",
    "\n",
    "\n",
    "    # Clear memory\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()  # Clear cached memory\n",
    "        torch.cuda.manual_seed_all(42)  # Re-seed\n",
    "\n",
    "    # Wait for 5-10 seconds before the next run\n",
    "\n",
    "    # End MLflow run\n",
    "    mlflow.end_run()\n",
    "    time.sleep(5)  # Sleep for 5 seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MPL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
