{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch 2.1.2+cu118\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "print(\"Using torch\", torch.__version__)\n",
    "import seaborn as sns\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "sns.set()\n",
    "torch.manual_seed(42) # Setting the seed\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ac_dll_grammar_vae import print_contact_info\n",
    "from ac_dll_grammar_vae.data import CFGEquationDataset\n",
    "from ac_dll_grammar_vae.data.alphabet import alphabet\n",
    "from ac_dll_grammar_vae.data.transforms import MathTokenEmbedding, RuleTokenEmbedding, ToTensor, Compose, PadSequencesToSameLengthV2, OneHotEncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)\n",
    "\n",
    "# GPU operations have a separate seed we also want to set\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
    "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Embedding:\n",
    "+ Using Math Token Embedding Class\n",
    "\n",
    "{'+': 1,\n",
    " '-': 2,\n",
    " '3': 3,\n",
    " 'sqrt': 4,\n",
    " 'exp': 5,\n",
    " '(': 6,\n",
    " 'sin': 7,\n",
    " '/': 8,\n",
    " 'x': 9,\n",
    " ')': 10,\n",
    " '*': 11,\n",
    " 'log': 12,\n",
    " 'cos': 13,\n",
    " '2': 14,\n",
    " '1': 15,\n",
    " ' ': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 1,\n",
       " '3': 2,\n",
       " 'sqrt': 3,\n",
       " '-': 4,\n",
       " '+': 5,\n",
       " '*': 6,\n",
       " '1': 7,\n",
       " '(': 8,\n",
       " '/': 9,\n",
       " '2': 10,\n",
       " 'sin': 11,\n",
       " 'cos': 12,\n",
       " 'log': 13,\n",
       " ')': 14,\n",
       " 'exp': 15,\n",
       " ' ': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = MathTokenEmbedding(alphabet=alphabet)\n",
    "emb.token_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: Data ['cos', '(', '(', '1', ')', ')', '+', '2']\n",
      "Encoded Example: Data [12, 8, 8, 7, 14, 14, 5, 10]\n"
     ]
    }
   ],
   "source": [
    "#Example Data\n",
    "data = CFGEquationDataset()\n",
    "#Example Encoding:\n",
    "print(f'Example: Data {data[42]}')\n",
    "encoded_data = emb.embed(data[42])\n",
    "print(f'Encoded Example: Data {encoded_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Example: Data ['cos', '(', '(', '1', ')', ')', '+', '2']\n",
    "+ Encoded Example: Data [13, 6, 6, 15, 10, 10, 1, 14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Training Dataset using CFG \n",
    " + Class CFGEquationDataset is used to generate the equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = CFGEquationDataset(\n",
    "        n_samples=100000,\n",
    "        transform=Compose([\n",
    "            MathTokenEmbedding(alphabet),\n",
    "            ToTensor(dtype=torch.uint8)\n",
    "        ]))\n",
    "\n",
    "#Batch Size:\n",
    "batch_size = 100\n",
    "MAX_SEQ_LEN = 21\n",
    "collate_fn = PadSequencesToSameLengthV2(padding_value=0, max_length=21)\n",
    "training_loader = DataLoader(dataset=training,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=PadSequencesToSameLengthV2(padding_value=0, max_length=21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the Embedded equations into one hot encoded vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000, 21, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehotencoder = OneHotEncode(alphabet)\n",
    "one_hot_encoded_training = []\n",
    "for batch in training_loader:\n",
    "  try:\n",
    "    one_hot_encoded_batch = onehotencoder(batch)\n",
    "  except Exception as e:\n",
    "    print(batch)\n",
    "    continue\n",
    "  one_hot_encoded_training.append(one_hot_encoded_batch.numpy())\n",
    "one_hot_encoded_training = np.array(one_hot_encoded_training)\n",
    "one_hot_encoded_training_tensor = torch.Tensor(one_hot_encoded_training)\n",
    "one_hot_encoded_training_tensor = one_hot_encoded_training_tensor.view(one_hot_encoded_training_tensor.shape[0]*one_hot_encoded_training_tensor.shape[1],one_hot_encoded_training_tensor.shape[2],one_hot_encoded_training_tensor.shape[3])\n",
    "one_hot_encoded_training_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating final dataloader for model which is one-hot-encoded:\n",
    " + Setting Maximum equation length to 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "MAX_SEQ_LEN = 21\n",
    "alphabet_length = len(alphabet) + 1\n",
    "one_hot_encoded_training_loader = DataLoader(dataset=one_hot_encoded_training_tensor,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization for Character AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EqnAE(\n",
      "  (conv1): Conv1d(21, 2, kernel_size=(2,), stride=(1,))\n",
      "  (conv2): Conv1d(2, 3, kernel_size=(3,), stride=(1,))\n",
      "  (conv3): Conv1d(3, 4, kernel_size=(4,), stride=(1,))\n",
      "  (bn1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn4): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=40, out_features=100, bias=True)\n",
      "  (fc_latent): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (rev_latent): Linear(in_features=10, out_features=100, bias=True)\n",
      "  (gru1): GRU(100, 100, batch_first=True)\n",
      "  (gru2): GRU(100, 100, batch_first=True)\n",
      "  (gru3): GRU(100, 100, batch_first=True)\n",
      "  (fc_final): Linear(in_features=100, out_features=16, bias=True)\n",
      "  (time_distributed): Linear(in_features=100, out_features=16, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from models import EqnAE\n",
    "# Model Initialization\n",
    "model = EqnAE(alphabet_length,MAX_SEQ_LEN)\n",
    "model.to(device)\n",
    "#Lossa\n",
    "BCELoss = nn.BCELoss(reduction=\"sum\")\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train_EqnAE\n",
    "train_EqnAE(model, one_hot_encoded_training_loader,BCELoss, optimizer, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!! Be careful with saving:\n",
    "torch.save(model.state_dict(), './saved/models/EQN_AE_BCE_Loss.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EqnAE(\n",
       "  (conv1): Conv1d(21, 2, kernel_size=(2,), stride=(1,))\n",
       "  (conv2): Conv1d(2, 3, kernel_size=(3,), stride=(1,))\n",
       "  (conv3): Conv1d(3, 4, kernel_size=(4,), stride=(1,))\n",
       "  (bn1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn4): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=40, out_features=100, bias=True)\n",
       "  (fc_latent): Linear(in_features=100, out_features=10, bias=True)\n",
       "  (rev_latent): Linear(in_features=10, out_features=100, bias=True)\n",
       "  (gru1): GRU(100, 100, batch_first=True)\n",
       "  (gru2): GRU(100, 100, batch_first=True)\n",
       "  (gru3): GRU(100, 100, batch_first=True)\n",
       "  (fc_final): Linear(in_features=100, out_features=16, bias=True)\n",
       "  (time_distributed): Linear(in_features=100, out_features=16, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EqnAE(alphabet_length, MAX_SEQ_LEN)\n",
    "model.load_state_dict(torch.load('./saved/models/EQN_AE_BCE_Loss.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Test Dataset and Dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CFGEquationDataset(\n",
    "        n_samples=1000,\n",
    "        transform=Compose([\n",
    "            MathTokenEmbedding(alphabet),\n",
    "            ToTensor(dtype=torch.uint8)\n",
    "        ]))\n",
    "\n",
    "#Batch Size:\n",
    "batch_size = 100\n",
    "MAX_SEQ_LEN = 21\n",
    "collate_fn = PadSequencesToSameLengthV2(padding_value=0, max_length=21)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=PadSequencesToSameLengthV2(padding_value=0, max_length=21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_testing = []\n",
    "for batch in test_loader:\n",
    "  try:\n",
    "    one_hot_encoded_batch = onehotencoder(batch)\n",
    "  except Exception as e:\n",
    "    print(batch)\n",
    "    continue\n",
    "  #print(one_hot_encoded_batch.shape)\n",
    "  one_hot_encoded_testing.append(one_hot_encoded_batch.numpy())\n",
    "one_hot_encoded_testing = np.array(one_hot_encoded_testing)\n",
    "one_hot_encoded_testing_tensor = torch.Tensor(one_hot_encoded_testing)\n",
    "one_hot_encoded_testing_tensor = one_hot_encoded_testing_tensor.view(one_hot_encoded_testing_tensor.shape[0]*one_hot_encoded_testing_tensor.shape[1],one_hot_encoded_testing_tensor.shape[2],one_hot_encoded_testing_tensor.shape[3])\n",
    "one_hot_encoded_testing_tensor.shape\n",
    "one_hot_encoded_testing_loader = DataLoader(dataset=one_hot_encoded_testing_tensor,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding and visualizing some outputs:\n",
    "+ One hot decode into embedding and then use idxtotoken to convert to equations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Equation: cos(1)-(3)+x           \n",
      "AE Decoded Equation: cos21sqrt-/log(x))expexpsinsinsinsinsinsinsinsin \n",
      "\n",
      "Actual Equation: 1*3                  \n",
      "AE Decoded Equation: 1log3x(**cossincos222222sqrtsqrtsqrtsqrtsqrt \n",
      "\n",
      "Actual Equation: 1                    \n",
      "AE Decoded Equation: -(3/cossqrt*sqrtsqrtsqrt+++++++++++ \n",
      "\n",
      "Actual Equation: 1                    \n",
      "AE Decoded Equation: -(3/cossqrt*sqrtsqrtsqrt+++++++++++ \n",
      "\n",
      "Actual Equation: 1                    \n",
      "AE Decoded Equation: -(3/cossqrt*sqrtsqrtsqrt+++++++++++ \n",
      "\n",
      "Actual Equation: 1*3                  \n",
      "AE Decoded Equation: 1log3x(**cossincos222222sqrtsqrtsqrtsqrtsqrt \n",
      "\n",
      "Actual Equation: 3                    \n",
      "AE Decoded Equation: 3(2222    expexpexpexpexpexpexp**** \n",
      "\n",
      "Actual Equation: sin(1/x-2)             \n",
      "AE Decoded Equation: sinlogcosxsqrt3x+//2) ) **expexpexpexp \n",
      "\n",
      "Actual Equation: 1                    \n",
      "AE Decoded Equation: -(3/cossqrt*sqrtsqrtsqrt+++++++++++ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "recon_batch_iter = iter(one_hot_encoded_testing_loader)\n",
    "recon_batch = next(recon_batch_iter)\n",
    "one_hot_decoded = []\n",
    "one_hot_decoded_recon = []\n",
    "for sample in recon_batch_iter:\n",
    "  sample = sample.to(device)\n",
    "  recon = model(sample)\n",
    "  for idx,ele in enumerate(recon):\n",
    "    max_indices = torch.argmax(ele, dim=1)\n",
    "    one_hot = torch.zeros_like(ele) \n",
    "    one_hot[torch.arange(ele.size(0)), max_indices] = 1\n",
    "    embd = torch.argmax(one_hot, dim=1)\n",
    "    one_hot_decoded.append(emb.decode(torch.argmax(sample[idx], dim=1)))\n",
    "    one_hot_decoded_recon.append(emb.decode(embd))\n",
    "    break\n",
    "\n",
    "for idx, ele in enumerate(one_hot_decoded_recon[:10]):\n",
    "  print('Actual Equation:', ''.join(one_hot_decoded[idx]))\n",
    "  print('AE Decoded Equation:', ''.join(one_hot_decoded_recon[idx]),'\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the latent space by PCA(2D) for some sample equations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import visualize_latent_space_Eqn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "from models import EqnVAE\n",
    "from train import train_EqnVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization for Character VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EqnVAE(\n",
      "  (conv1): Conv1d(21, 2, kernel_size=(2,), stride=(1,))\n",
      "  (conv2): Conv1d(2, 3, kernel_size=(3,), stride=(1,))\n",
      "  (conv3): Conv1d(3, 4, kernel_size=(4,), stride=(1,))\n",
      "  (bn1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn4): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=40, out_features=100, bias=True)\n",
      "  (fc_mean): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (fc_logvar): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (rev_latent): Linear(in_features=10, out_features=100, bias=True)\n",
      "  (gru1): GRU(100, 100, batch_first=True)\n",
      "  (gru2): GRU(100, 100, batch_first=True)\n",
      "  (gru3): GRU(100, 100, batch_first=True)\n",
      "  (fc_final): Linear(in_features=100, out_features=16, bias=True)\n",
      "  (time_distributed): Linear(in_features=100, out_features=16, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model Initialization\n",
    "alphabet_length = len(alphabet) + 1\n",
    "model = EqnVAE(alphabet_length,MAX_SEQ_LEN)\n",
    "model.to(device)\n",
    "#Loss\n",
    "vaeLoss = model.vae_loss\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-03)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average loss: 1492.55557656\n",
      "====> Epoch: 1 Average loss: 1471.09773828\n",
      "====> Epoch: 2 Average loss: 1458.59959500\n",
      "====> Epoch: 3 Average loss: 1450.24223125\n",
      "====> Epoch: 4 Average loss: 1444.21629000\n",
      "====> Epoch: 5 Average loss: 1439.44751872\n",
      "====> Epoch: 6 Average loss: 1435.45321866\n",
      "====> Epoch: 7 Average loss: 1432.06335244\n",
      "====> Epoch: 8 Average loss: 1429.05706946\n",
      "====> Epoch: 9 Average loss: 1426.31681716\n",
      "====> Epoch: 10 Average loss: 1423.85109236\n",
      "====> Epoch: 11 Average loss: 1421.58311964\n",
      "====> Epoch: 12 Average loss: 1419.47475049\n",
      "====> Epoch: 13 Average loss: 1417.49201887\n",
      "====> Epoch: 14 Average loss: 1415.67986107\n",
      "====> Epoch: 15 Average loss: 1413.94596692\n",
      "====> Epoch: 16 Average loss: 1412.32364415\n",
      "====> Epoch: 17 Average loss: 1410.80080154\n",
      "====> Epoch: 18 Average loss: 1409.34327565\n",
      "====> Epoch: 19 Average loss: 1407.96357970\n",
      "====> Epoch: 20 Average loss: 1406.66743105\n",
      "====> Epoch: 21 Average loss: 1405.41452796\n",
      "====> Epoch: 22 Average loss: 1404.29951126\n",
      "====> Epoch: 23 Average loss: 1403.14961610\n",
      "====> Epoch: 24 Average loss: 1402.10110971\n",
      "====> Epoch: 25 Average loss: 1401.07526802\n",
      "====> Epoch: 26 Average loss: 1400.10937634\n",
      "====> Epoch: 27 Average loss: 1399.18724664\n",
      "====> Epoch: 28 Average loss: 1398.29439923\n",
      "====> Epoch: 29 Average loss: 1397.46934339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1397.469343388021"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_EqnVAE(model,one_hot_encoded_training_loader,vaeLoss,optimizer,num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!! Be careful with saving:\n",
    "torch.save(model.state_dict(), './saved/models/EQN_VAE_BCE_Loss.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EqnVAE(\n",
       "  (conv1): Conv1d(21, 2, kernel_size=(2,), stride=(1,))\n",
       "  (conv2): Conv1d(2, 3, kernel_size=(3,), stride=(1,))\n",
       "  (conv3): Conv1d(3, 4, kernel_size=(4,), stride=(1,))\n",
       "  (bn1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn4): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=40, out_features=100, bias=True)\n",
       "  (fc_mean): Linear(in_features=100, out_features=10, bias=True)\n",
       "  (fc_logvar): Linear(in_features=100, out_features=10, bias=True)\n",
       "  (rev_latent): Linear(in_features=10, out_features=100, bias=True)\n",
       "  (gru1): GRU(100, 100, batch_first=True)\n",
       "  (gru2): GRU(100, 100, batch_first=True)\n",
       "  (gru3): GRU(100, 100, batch_first=True)\n",
       "  (fc_final): Linear(in_features=100, out_features=16, bias=True)\n",
       "  (time_distributed): Linear(in_features=100, out_features=16, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EqnVAE(alphabet_length,MAX_SEQ_LEN)\n",
    "model.load_state_dict(torch.load('./saved/models/EQN_VAE_BCE_Loss.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Test Dataset and Dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CFGEquationDataset(\n",
    "        n_samples=1000,\n",
    "        transform=Compose([\n",
    "            MathTokenEmbedding(alphabet),\n",
    "            ToTensor(dtype=torch.uint8)\n",
    "        ]))\n",
    "\n",
    "#Batch Size:\n",
    "batch_size = 100\n",
    "MAX_SEQ_LEN = 21\n",
    "collate_fn = PadSequencesToSameLengthV2(padding_value=0, max_length=21)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=PadSequencesToSameLengthV2(padding_value=0, max_length=21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_testing = []\n",
    "for batch in test_loader:\n",
    "  try:\n",
    "    one_hot_encoded_batch = onehotencoder(batch)\n",
    "  except Exception as e:\n",
    "    print(batch)\n",
    "    continue\n",
    "  #print(one_hot_encoded_batch.shape)\n",
    "  one_hot_encoded_testing.append(one_hot_encoded_batch.numpy())\n",
    "one_hot_encoded_testing = np.array(one_hot_encoded_testing)\n",
    "one_hot_encoded_testing_tensor = torch.Tensor(one_hot_encoded_testing)\n",
    "one_hot_encoded_testing_tensor = one_hot_encoded_testing_tensor.view(one_hot_encoded_testing_tensor.shape[0]*one_hot_encoded_testing_tensor.shape[1],one_hot_encoded_testing_tensor.shape[2],one_hot_encoded_testing_tensor.shape[3])\n",
    "one_hot_encoded_testing_tensor.shape\n",
    "one_hot_encoded_testing_loader = DataLoader(dataset=one_hot_encoded_testing_tensor,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding and visualizing some outputs:\n",
    "+ One hot decode into embedding and then use idxtotoken to convert to equations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Equation: x                    \n",
      "VAE Decoded Equation: xexp*cos --2222222222//// \n",
      "\n",
      "Actual Equation: 1-1+3                \n",
      "VAE Decoded Equation: 1322+xxxxx x///////// \n",
      "\n",
      "Actual Equation: cos(1)                 \n",
      "VAE Decoded Equation: x(1sqrtexpsin+*2*2+))))))))2 \n",
      "\n",
      "Actual Equation: 1                    \n",
      "VAE Decoded Equation: 1((-------**logloglogloglogloglogloglog \n",
      "\n",
      "Actual Equation: 3                    \n",
      "VAE Decoded Equation: exp sqrtsqrtsqrtsqrtsqrtsqrtsqrt---111111111 \n",
      "\n",
      "Actual Equation: 3-2+3+3              \n",
      "VAE Decoded Equation: *(1sqrt2x++3---///////)) \n",
      "\n",
      "Actual Equation: 1                    \n",
      "VAE Decoded Equation: 1sin22222 333xxxxloglogloglogloglog \n",
      "\n",
      "Actual Equation: 3                    \n",
      "VAE Decoded Equation: exp/sin((coscoscoscos--1111xxxxxx \n",
      "\n",
      "Actual Equation: x                    \n",
      "VAE Decoded Equation: xlog-cossinsinsin----   sqrtsqrtsqrtsqrtsqrtsqrtsqrt \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "recon_batch_iter = iter(one_hot_encoded_testing_loader)\n",
    "recon_batch = next(recon_batch_iter)\n",
    "one_hot_decoded = []\n",
    "one_hot_decoded_recon = []\n",
    "for sample in recon_batch_iter:\n",
    "  sample = sample.to(device)\n",
    "  recon, _, _ = model(sample)\n",
    "  for idx,ele in enumerate(recon):\n",
    "    max_indices = torch.argmax(ele, dim=1)\n",
    "    one_hot = torch.zeros_like(ele) \n",
    "    one_hot[torch.arange(ele.size(0)), max_indices] = 1\n",
    "    embd = torch.argmax(one_hot, dim=1)\n",
    "    one_hot_decoded.append(emb.decode(torch.argmax(sample[idx], dim=1)))\n",
    "    one_hot_decoded_recon.append(emb.decode(embd))\n",
    "    break\n",
    "\n",
    "for idx, ele in enumerate(one_hot_decoded_recon[:10]):\n",
    "  print('Actual Equation:', ''.join(one_hot_decoded[idx]))\n",
    "  print('VAE Decoded Equation:', ''.join(one_hot_decoded_recon[idx]),'\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the latent space by PCA(2D) for some sample equations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\soupt\\OneDrive - stud.uni-stuttgart.de\\AI LAB\\Project\\Repo\\Character&GrammarVAE.ipynb Cell 40\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/soupt/OneDrive%20-%20stud.uni-stuttgart.de/AI%20LAB/Project/Repo/Character%26GrammarVAE.ipynb#Y122sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mvisualize\u001b[39;00m \u001b[39mimport\u001b[39;00m visualize_latent_space_Eqn\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/soupt/OneDrive%20-%20stud.uni-stuttgart.de/AI%20LAB/Project/Repo/Character%26GrammarVAE.ipynb#Y122sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/soupt/OneDrive%20-%20stud.uni-stuttgart.de/AI%20LAB/Project/Repo/Character%26GrammarVAE.ipynb#Y122sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m one_hot_encoded_training_loader \u001b[39m=\u001b[39m one_hot_encoded_training_loader\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/soupt/OneDrive%20-%20stud.uni-stuttgart.de/AI%20LAB/Project/Repo/Character%26GrammarVAE.ipynb#Y122sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m visualize_latent_space_Eqn(model, one_hot_encoded_training_loader)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "from visualize import visualize_latent_space_Eqn\n",
    "model.to(device)\n",
    "visualize_latent_space_Eqn(model, one_hot_encoded_training_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MPL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
